{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pascal.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "cnZCucbpq_c1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Important: This notebook will only work with fastai-0.7.x. Do not try to run any fastai-1.x code from this path in the repository because it will load fastai-0.7.x**"
      ]
    },
    {
      "metadata": {
        "id": "Nwjlilz7rCKs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q \"fastai==0.7.0\" Pillow==4.1.1 torchtext==0.2.3\n",
        "!apt-get -qq install -y libsm6 libxext6 && pip install -q -U opencv-python\n",
        "\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "# !apt update -q\n",
        "!apt install -y libsm6 libxext6\n",
        "\n",
        "from os import path\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "torch_whl = f\"http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl\"\n",
        "!pip install -q {torch_whl} torchvision image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "87F-NE5nq_c6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NPxMRc5orOC0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget http://pjreddie.com/media/files/VOCtrainval_06-Nov-2007.tar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P_ikGg9irUyL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "!tar -xvf VOCtrainval_06-Nov-2007.tar\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RaRfAkqTsLCS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!mkdir data/pascal\n",
        "!mkdir data/pascal/VOCdevkit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YXu-L_3hsEXt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "!mv VOCdevkit  data/pascal/VOCdevkit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hVBTlm_E7E5s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mv -v data/pascal/VOCdevkit/VOCdevkit/* data/pascal/VOCdevkit/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BBVa-Q2qra5k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/coco-dataset/external/PASCAL_VOC.zip\n",
        "!unzip PASCAL_VOC.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CjlUef6XuBDi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mv -v PASCAL_VOC/* data/pascal/\n",
        "!ls data/pascal"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KDKa3manq_dB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from fastai.conv_learner import *\n",
        "from fastai.dataset import *\n",
        "\n",
        "from pathlib import Path\n",
        "import json\n",
        "from PIL import ImageDraw, ImageFont\n",
        "from matplotlib import patches, patheffects\n",
        "torch.cuda.set_device(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mn1SqNBzq_dF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pascal VOC"
      ]
    },
    {
      "metadata": {
        "id": "Xnvu613uq_dG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will be looking at the [Pascal VOC](http://host.robots.ox.ac.uk/pascal/VOC/) dataset. It's quite slow, so you may prefer to download from [this mirror](https://pjreddie.com/projects/pascal-voc-dataset-mirror/). There are two different competition/research datasets, from 2007 and 2012. We'll be using the 2007 version. You can use the larger 2012 for better results, or even combine them (but be careful to avoid data leakage between the validation sets if you do this).\n",
        "\n",
        "Unlike previous lessons, we are using the python 3 standard library `pathlib` for our paths and file access. Note that it returns an OS-specific class (on Linux, `PosixPath`) so your output may look a little different. Most libraries than take paths as input can take a pathlib object - although some (like `cv2`) can't, in which case you can use `str()` to convert it to a string."
      ]
    },
    {
      "metadata": {
        "id": "6WNb34Vqq_dI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PATH = Path('data/pascal')\n",
        "list(PATH.iterdir())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WSLX_qdQq_dQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As well as the images, there are also *annotations* - *bounding boxes* showing where each object is. These were hand labeled. The original version were in XML, which is a little hard to work with nowadays, so we uses the more recent JSON version which you can download from [this link](https://storage.googleapis.com/coco-dataset/external/PASCAL_VOC.zip).\n",
        "\n",
        "You can see here how `pathlib` includes the ability to open files (amongst many other capabilities)."
      ]
    },
    {
      "metadata": {
        "id": "TkVXmax23BO3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trn_j?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ULJ6ueMCq_dS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trn_j = json.load((PATH/'pascal_train2007.json').open())\n",
        "trn_j.keys()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9nvAjIH4q_dZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "IMAGES,ANNOTATIONS,CATEGORIES = ['images', 'annotations', 'categories']\n",
        "trn_j[IMAGES][:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NLsPRy7dq_de",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trn_j[ANNOTATIONS][:2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hyfiqHFQq_dl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trn_j[CATEGORIES][:4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9tFUT8mxq_dt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It's helpful to use constants instead of strings, since we get tab-completion and don't mistype."
      ]
    },
    {
      "metadata": {
        "id": "PZo0qJVQq_dv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "FILE_NAME,ID,IMG_ID,CAT_ID,BBOX = ['file_name','id','image_id','category_id','bbox']\n",
        "\n",
        "cats = {o[ID]:o['name'] for o in trn_j[CATEGORIES]}\n",
        "trn_fns = {o[ID]:o[FILE_NAME] for o in trn_j[IMAGES]}\n",
        "trn_ids = [o[ID] for o in trn_j[IMAGES]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i8spRUHv7h5c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "31c644cd-59b6-4176-ddae-e63fa25629c6"
      },
      "cell_type": "code",
      "source": [
        "#homework, find the image with highest number of objects\n",
        "\n",
        "img_ids = [o['image_id'] for o in trn_j[ANNOTATIONS] if not o['ignore']]\n",
        "from statistics import mode\n",
        "mode(img_ids)\n",
        "trn_anno = collections.defaultdict(lambda:[])\n",
        "for o in trn_j[ANNOTATIONS]:\n",
        "  if not o['ignore']:\n",
        "    if o['image_id'] == 7953:\n",
        "      print(o)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'segmentation': [[311, 166, 311, 214, 327, 214, 327, 166]], 'area': 768, 'iscrowd': 0, 'image_id': 7953, 'bbox': [311, 166, 16, 48], 'category_id': 15, 'id': 6131, 'ignore': 0}\n",
            "{'segmentation': [[257, 191, 257, 217, 284, 217, 284, 191]], 'area': 702, 'iscrowd': 0, 'image_id': 7953, 'bbox': [257, 191, 27, 26], 'category_id': 15, 'id': 6132, 'ignore': 0}\n",
            "{'segmentation': [[219, 192, 219, 220, 240, 220, 240, 192]], 'area': 588, 'iscrowd': 0, 'image_id': 7953, 'bbox': [219, 192, 21, 28], 'category_id': 15, 'id': 6133, 'ignore': 0}\n",
            "{'segmentation': [[192, 175, 192, 220, 213, 220, 213, 175]], 'area': 945, 'iscrowd': 0, 'image_id': 7953, 'bbox': [192, 175, 21, 45], 'category_id': 15, 'id': 6134, 'ignore': 0}\n",
            "{'segmentation': [[104, 170, 104, 221, 126, 221, 126, 170]], 'area': 1122, 'iscrowd': 0, 'image_id': 7953, 'bbox': [104, 170, 22, 51], 'category_id': 15, 'id': 6135, 'ignore': 0}\n",
            "{'segmentation': [[124, 177, 124, 223, 143, 223, 143, 177]], 'area': 874, 'iscrowd': 0, 'image_id': 7953, 'bbox': [124, 177, 19, 46], 'category_id': 15, 'id': 6136, 'ignore': 0}\n",
            "{'segmentation': [[85, 173, 85, 226, 104, 226, 104, 173]], 'area': 1007, 'iscrowd': 0, 'image_id': 7953, 'bbox': [85, 173, 19, 53], 'category_id': 15, 'id': 6137, 'ignore': 0}\n",
            "{'segmentation': [[67, 167, 67, 226, 89, 226, 89, 167]], 'area': 1298, 'iscrowd': 0, 'image_id': 7953, 'bbox': [67, 167, 22, 59], 'category_id': 15, 'id': 6138, 'ignore': 0}\n",
            "{'segmentation': [[40, 174, 40, 228, 57, 228, 57, 174]], 'area': 918, 'iscrowd': 0, 'image_id': 7953, 'bbox': [40, 174, 17, 54], 'category_id': 15, 'id': 6139, 'ignore': 0}\n",
            "{'segmentation': [[27, 173, 27, 236, 43, 236, 43, 173]], 'area': 1008, 'iscrowd': 0, 'image_id': 7953, 'bbox': [27, 173, 16, 63], 'category_id': 15, 'id': 6140, 'ignore': 0}\n",
            "{'segmentation': [[263, 214, 263, 298, 319, 298, 319, 214]], 'area': 4704, 'iscrowd': 0, 'image_id': 7953, 'bbox': [263, 214, 56, 84], 'category_id': 15, 'id': 6143, 'ignore': 0}\n",
            "{'segmentation': [[154, 249, 154, 290, 190, 290, 190, 249]], 'area': 1476, 'iscrowd': 0, 'image_id': 7953, 'bbox': [154, 249, 36, 41], 'category_id': 15, 'id': 6144, 'ignore': 0}\n",
            "{'segmentation': [[195, 364, 195, 392, 282, 392, 282, 364]], 'area': 2436, 'iscrowd': 0, 'image_id': 7953, 'bbox': [195, 364, 87, 28], 'category_id': 15, 'id': 6145, 'ignore': 0}\n",
            "{'segmentation': [[94, 209, 94, 270, 136, 270, 136, 209]], 'area': 2562, 'iscrowd': 0, 'image_id': 7953, 'bbox': [94, 209, 42, 61], 'category_id': 15, 'id': 6146, 'ignore': 0}\n",
            "{'segmentation': [[120, 209, 120, 249, 151, 249, 151, 209]], 'area': 1240, 'iscrowd': 0, 'image_id': 7953, 'bbox': [120, 209, 31, 40], 'category_id': 15, 'id': 6147, 'ignore': 0}\n",
            "{'segmentation': [[50, 236, 50, 292, 92, 292, 92, 236]], 'area': 2352, 'iscrowd': 0, 'image_id': 7953, 'bbox': [50, 236, 42, 56], 'category_id': 15, 'id': 6148, 'ignore': 0}\n",
            "{'segmentation': [[69, 258, 69, 339, 115, 339, 115, 258]], 'area': 3726, 'iscrowd': 0, 'image_id': 7953, 'bbox': [69, 258, 46, 81], 'category_id': 15, 'id': 6149, 'ignore': 0}\n",
            "{'segmentation': [[143, 354, 143, 395, 208, 395, 208, 354]], 'area': 2665, 'iscrowd': 0, 'image_id': 7953, 'bbox': [143, 354, 65, 41], 'category_id': 2, 'id': 6150, 'ignore': 0}\n",
            "{'segmentation': [[255, 273, 255, 309, 321, 309, 321, 273]], 'area': 2376, 'iscrowd': 0, 'image_id': 7953, 'bbox': [255, 273, 66, 36], 'category_id': 2, 'id': 6155, 'ignore': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0SniwyOUq_dz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d093e388-6635-403a-e67e-60d1e7e68655"
      },
      "cell_type": "code",
      "source": [
        "list((PATH/'VOCdevkit'/'VOC2007').iterdir())"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('data/pascal/VOCdevkit/VOC2007/ImageSets'),\n",
              " PosixPath('data/pascal/VOCdevkit/VOC2007/Annotations'),\n",
              " PosixPath('data/pascal/VOCdevkit/VOC2007/JPEGImages'),\n",
              " PosixPath('data/pascal/VOCdevkit/VOC2007/SegmentationObject'),\n",
              " PosixPath('data/pascal/VOCdevkit/VOC2007/SegmentationClass')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "1E2wEXBKq_d5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "JPEGS = 'VOCdevkit/VOC2007/JPEGImages'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1fv932hRq_d9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "d05c6a59-7027-4f1c-a798-c840ebdee5b3"
      },
      "cell_type": "code",
      "source": [
        "IMG_PATH = PATH/JPEGS\n",
        "list(IMG_PATH.iterdir())[:5]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('data/pascal/VOCdevkit/VOC2007/JPEGImages/001287.jpg'),\n",
              " PosixPath('data/pascal/VOCdevkit/VOC2007/JPEGImages/008728.jpg'),\n",
              " PosixPath('data/pascal/VOCdevkit/VOC2007/JPEGImages/005541.jpg'),\n",
              " PosixPath('data/pascal/VOCdevkit/VOC2007/JPEGImages/009526.jpg'),\n",
              " PosixPath('data/pascal/VOCdevkit/VOC2007/JPEGImages/007230.jpg')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "u-C1SmvOjiXS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "b8930d99-c7c9-4175-f4b0-d3fb4bf958be"
      },
      "cell_type": "code",
      "source": [
        "oi = open_image('data/pascal/VOCdevkit/VOC2007/JPEGImages/001287.jpg')\n",
        "show_im"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.1098 , 0.1098 , 0.1098 ],\n",
              "        [0.13333, 0.13333, 0.13333],\n",
              "        [0.12941, 0.12941, 0.12941],\n",
              "        ...,\n",
              "        [1.     , 1.     , 1.     ],\n",
              "        [1.     , 1.     , 1.     ],\n",
              "        [1.     , 1.     , 1.     ]],\n",
              "\n",
              "       [[0.16078, 0.16078, 0.16078],\n",
              "        [0.11765, 0.11765, 0.11765],\n",
              "        [0.12941, 0.12941, 0.12941],\n",
              "        ...,\n",
              "        [1.     , 1.     , 1.     ],\n",
              "        [1.     , 1.     , 1.     ],\n",
              "        [1.     , 1.     , 1.     ]],\n",
              "\n",
              "       [[0.11765, 0.11765, 0.11765],\n",
              "        [0.1098 , 0.1098 , 0.1098 ],\n",
              "        [0.09804, 0.09804, 0.09804],\n",
              "        ...,\n",
              "        [1.     , 1.     , 1.     ],\n",
              "        [1.     , 1.     , 1.     ],\n",
              "        [1.     , 1.     , 1.     ]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.5098 , 0.36078, 0.32549],\n",
              "        [0.48627, 0.33725, 0.29412],\n",
              "        [0.65882, 0.5098 , 0.45882],\n",
              "        ...,\n",
              "        [0.15294, 0.27059, 0.3098 ],\n",
              "        [0.12157, 0.23922, 0.27843],\n",
              "        [0.11765, 0.23529, 0.27451]],\n",
              "\n",
              "       [[0.43529, 0.2902 , 0.25882],\n",
              "        [0.50196, 0.35686, 0.32157],\n",
              "        [0.59216, 0.43529, 0.39608],\n",
              "        ...,\n",
              "        [0.16471, 0.28235, 0.32157],\n",
              "        [0.12941, 0.23922, 0.28235],\n",
              "        [0.13333, 0.25098, 0.2902 ]],\n",
              "\n",
              "       [[0.37647, 0.24706, 0.22745],\n",
              "        [0.46667, 0.32941, 0.30588],\n",
              "        [0.56471, 0.39608, 0.36078],\n",
              "        ...,\n",
              "        [0.13725, 0.25098, 0.28235],\n",
              "        [0.12941, 0.23529, 0.27059],\n",
              "        [0.14118, 0.2549 , 0.28627]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "8cmfjn5Bq_eC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Each image has a unique ID."
      ]
    },
    {
      "metadata": {
        "id": "Bd0BDJ7pq_eE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18ad7b98-969d-415e-8cab-79c90fcc77fc"
      },
      "cell_type": "code",
      "source": [
        "im0_d = trn_j[IMAGES][0]\n",
        "im0_d[FILE_NAME],im0_d[ID]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('000012.jpg', 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "tb57wlG7q_eM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A `defaultdict` is useful any time you want to have a default dictionary entry for new keys. Here we create a dict from image IDs to a list of annotations (tuple of bounding box and class id).\n",
        "\n",
        "We convert VOC's height/width into top-left/bottom-right, and switch x/y coords to be consistent with numpy."
      ]
    },
    {
      "metadata": {
        "id": "97wu1-Lcq_eO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def hw_bb(bb): return np.array([bb[1], bb[0], bb[3]+bb[1]-1, bb[2]+bb[0]-1])\n",
        "\n",
        "trn_anno = collections.defaultdict(lambda:[])\n",
        "for o in trn_j[ANNOTATIONS]:\n",
        "    if not o['ignore']:\n",
        "        bb = o[BBOX]\n",
        "        bb = hw_bb(bb)\n",
        "        trn_anno[o[IMG_ID]].append((bb,o[CAT_ID]))\n",
        "        \n",
        "len(trn_anno)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rugSbkbZq_eb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "im_a = trn_anno[im0_d[ID]]; im_a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ShRFBM5zq_ek",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "im0_a = im_a[0]; im0_a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3_C0Wfvsq_ey",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cats[7]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hPYNLQs8q_e4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trn_anno[17]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gfx12p2lq_e9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cats[15],cats[13]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hO3J1jDyq_fC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Some libs take VOC format bounding boxes, so this let's us convert back when required:"
      ]
    },
    {
      "metadata": {
        "id": "dWhmjnfbq_fD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bb_voc = [155, 96, 196, 174]\n",
        "bb_fastai = hw_bb(bb_voc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BBXDXKz0q_fH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def bb_hw(a): return np.array([a[1],a[0],a[3]-a[1]+1,a[2]-a[0]+1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QywaRKOkq_fK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f'expected: {bb_voc}, actual: {bb_hw(bb_fastai)}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UAx6XN9Dq_fS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can use [Visual Studio Code](https://code.visualstudio.com/) (vscode - open source editor that comes with recent versions of Anaconda, or can be installed separately), or most editors and IDEs, to find out all about the `open_image` function. vscode things to know:\n",
        "\n",
        "- Command palette (<kbd>Ctrl-shift-p</kbd>)\n",
        "- Select interpreter (for fastai env)\n",
        "- Select terminal shell\n",
        "- Go to symbol (<kbd>Ctrl-t</kbd>)\n",
        "- Find references (<kbd>Shift-F12</kbd>)\n",
        "- Go to definition (<kbd>F12</kbd>)\n",
        "- Go back (<kbd>alt-left</kbd>)\n",
        "- View documentation\n",
        "- Hide sidebar (<kbd>Ctrl-b</kbd>)\n",
        "- Zen mode (<kbd>Ctrl-k,z</kbd>)"
      ]
    },
    {
      "metadata": {
        "id": "Ydu9Q3Mnq_fS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "im = open_image(IMG_PATH/im0_d[FILE_NAME])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "seJotBi0q_fW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Matplotlib's `plt.subplots` is a really useful wrapper for creating plots, regardless of whether you have more than one subplot. Note that Matplotlib has an optional object-oriented API which I think is much easier to understand and use (although few examples online use it!)"
      ]
    },
    {
      "metadata": {
        "id": "SxBr1ng4q_fX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def show_img(im, figsize=None, ax=None):\n",
        "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
        "    ax.imshow(im)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F1Bg3ci8q_fd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A simple but rarely used trick to making text visible regardless of background is to use white text with black outline, or visa versa. Here's how to do it in matplotlib."
      ]
    },
    {
      "metadata": {
        "id": "isdkZr-8q_fe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def draw_outline(o, lw):\n",
        "    o.set_path_effects([patheffects.Stroke(\n",
        "        linewidth=lw, foreground='black'), patheffects.Normal()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WesdcSYOq_fh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that `*` in argument lists is the [splat operator](https://stackoverflow.com/questions/5239856/foggy-on-asterisk-in-python). In this case it's a little shortcut compared to writing out `b[-2],b[-1]`."
      ]
    },
    {
      "metadata": {
        "id": "TmhxftI3q_fi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def draw_rect(ax, b):\n",
        "    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor='white', lw=2))\n",
        "    draw_outline(patch, 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "va_TyFumq_fl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def draw_text(ax, xy, txt, sz=14):\n",
        "    text = ax.text(*xy, txt,\n",
        "        verticalalignment='top', color='white', fontsize=sz, weight='bold')\n",
        "    draw_outline(text, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U2kZONbCq_fp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ax = show_img(im)\n",
        "b = bb_hw(im0_a[0])\n",
        "draw_rect(ax, b)\n",
        "draw_text(ax, b[:2], cats[im0_a[1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b4o7wYBtq_fu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def draw_im(im, ann):\n",
        "    ax = show_img(im, figsize=(16,8))\n",
        "    for b,c in ann:\n",
        "        b = bb_hw(b)\n",
        "        draw_rect(ax, b)\n",
        "        draw_text(ax, b[:2], cats[c], sz=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bnh_qp8uq_fx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def draw_idx(i):\n",
        "    im_a = trn_anno[i]\n",
        "    im = open_image(IMG_PATH/trn_fns[i])\n",
        "    print(im.shape)\n",
        "    draw_im(im, im_a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hh4-T_HZq_f0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "draw_idx(17)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9JANuskUq_f4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Largest item classifier"
      ]
    },
    {
      "metadata": {
        "id": "u3ZfXbZoq_f5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A *lambda function* is simply a way to define an anonymous function inline. Here we use it to describe how to sort the annotation for each image - by bounding box size (descending)."
      ]
    },
    {
      "metadata": {
        "id": "TtZKRuAHq_f6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_lrg(b):\n",
        "    if not b: raise Exception()\n",
        "    b = sorted(b, key=lambda x: np.product(x[0][-2:]-x[0][:2]), reverse=True)\n",
        "    return b[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bjn36mqHq_f-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trn_lrg_anno = {a: get_lrg(b) for a,b in trn_anno.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RCPptjlwq_gD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we have a dictionary from image id to a single bounding box - the largest for that image."
      ]
    },
    {
      "metadata": {
        "id": "5lCPHiWNq_gF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "b,c = trn_lrg_anno[23]\n",
        "b = bb_hw(b)\n",
        "ax = show_img(open_image(IMG_PATH/trn_fns[23]), figsize=(5,10))\n",
        "draw_rect(ax, b)\n",
        "draw_text(ax, b[:2], cats[c], sz=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZjVGgRRbq_gS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(PATH/'tmp').mkdir(exist_ok=True)\n",
        "CSV = PATH/'tmp/lrg.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4XY65YK-q_gW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Often it's easiest to simply create a CSV of the data you want to model, rather than trying to create a custom dataset. Here we use Pandas to help us create a CSV of the image filename and class."
      ]
    },
    {
      "metadata": {
        "id": "S2Anuzegq_gX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'fn': [trn_fns[o] for o in trn_ids],\n",
        "    'cat': [cats[trn_lrg_anno[o][1]] for o in trn_ids]}, columns=['fn','cat'])\n",
        "df.to_csv(CSV, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C536Fz7Hq_gc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f_model = resnet34\n",
        "sz=224\n",
        "bs=64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bPJHtWFTq_gg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From here it's just like Dogs vs Cats!"
      ]
    },
    {
      "metadata": {
        "id": "fWO-dv4Aq_gi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfms = tfms_from_model(f_model, sz, aug_tfms=transforms_side_on, crop_type=CropType.NO)\n",
        "md = ImageClassifierData.from_csv(PATH, JPEGS, CSV, tfms=tfms, bs=bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FvyrGwX7q_gn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x,y=next(iter(md.val_dl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y724O9agq_gr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "show_img(md.val_ds.denorm(to_np(x))[0]);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M1mZHpTUq_gy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn = ConvLearner.pretrained(f_model, md, metrics=[accuracy])\n",
        "learn.opt_fn = optim.Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HbPGaGcQq_g1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lrf=learn.lr_find(1e-5,100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y2cFbjVuq_g7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "When you LR finder graph looks like this, you can ask for more points on each end:"
      ]
    },
    {
      "metadata": {
        "id": "Z15Sdbqcq_g8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.sched.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HLEkXI_Mq_hB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.sched.plot(n_skip=5, n_skip_end=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mmPLm6e0q_hG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr = 2e-2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yv8BTiQdq_hK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lr, 1, cycle_len=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ddlLxManq_hP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lrs = np.array([lr/1000,lr/100,lr])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xwopNOCgq_hS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.freeze_to(-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EbsGcNtkq_hW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lrf=learn.lr_find(lrs/1000)\n",
        "learn.sched.plot(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-uimWlfdq_hb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lrs/5, 1, cycle_len=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G88-84U5q_hf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.unfreeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W0reo0wjq_hh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Accuracy isn't improving much - since many images have multiple different objects, it's going to be impossible to be that accurate."
      ]
    },
    {
      "metadata": {
        "id": "AvlzoO6tq_hi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lrs/5, 1, cycle_len=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sas--1Zgq_hp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('clas_one')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k9f15h7cq_hs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.load('clas_one')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RoqRf3oRq_hu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x,y = next(iter(md.val_dl))\n",
        "probs = F.softmax(predict_batch(learn.model, x), -1)\n",
        "x,preds = to_np(x),to_np(probs)\n",
        "preds = np.argmax(preds, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s-uxaUeuq_hy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can use the python debugger `pdb` to step through code.\n",
        "\n",
        "- `pdb.set_trace()` to set a breakpoint\n",
        "- `%debug` magic to trace an error\n",
        "\n",
        "Commands you need to know:\n",
        "\n",
        "- s / n / c\n",
        "- u / d\n",
        "- p\n",
        "- l"
      ]
    },
    {
      "metadata": {
        "id": "Uge0JHgAq_hz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(3, 4, figsize=(12, 8))\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    ima=md.val_ds.denorm(x)[i]\n",
        "    b = md.classes[preds[i]]\n",
        "    ax = show_img(ima, ax=ax)\n",
        "    draw_text(ax, (0,0), b)\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u9k2Zj6Sq_h4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It's doing a pretty good job of classifying the largest object!"
      ]
    },
    {
      "metadata": {
        "id": "gCgOrBjOq_h6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Bbox only"
      ]
    },
    {
      "metadata": {
        "id": "9EIHM8Rjq_h6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we'll try to find the bounding box of the largest object. This is simply a regression with 4 outputs. So we can use a CSV with multiple 'labels'."
      ]
    },
    {
      "metadata": {
        "id": "xdyXZKZBq_h6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BB_CSV = PATH/'tmp/bb.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QFB-w1Pwq_h9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bb = np.array([trn_lrg_anno[o][0] for o in trn_ids])\n",
        "bbs = [' '.join(str(p) for p in o) for o in bb]\n",
        "\n",
        "df = pd.DataFrame({'fn': [trn_fns[o] for o in trn_ids], 'bbox': bbs}, columns=['fn','bbox'])\n",
        "df.to_csv(BB_CSV, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-pljgNyVq_h_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BB_CSV.open().readlines()[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RdPsAXWqq_iH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f_model=resnet34\n",
        "sz=224\n",
        "bs=64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BxkwZ1OOq_iK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Set `continuous=True` to tell fastai this is a regression problem, which means it won't one-hot encode the labels, and will use MSE as the default crit.\n",
        "\n",
        "Note that we have to tell the transforms constructor that our labels are coordinates, so that it can handle the transforms correctly.\n",
        "\n",
        "Also, we use CropType.NO because we want to 'squish' the rectangular images into squares, rather than center cropping, so that we don't accidentally crop out some of the objects. (This is less of an issue in something like imagenet, where there is a single object to classify, and it's generally large and centrally located)."
      ]
    },
    {
      "metadata": {
        "id": "gILGAOwJq_iL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "augs = [RandomFlip(), \n",
        "        RandomRotate(30),\n",
        "        RandomLighting(0.1,0.1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dRKn0U8eq_iN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, aug_tfms=augs)\n",
        "md = ImageClassifierData.from_csv(PATH, JPEGS, BB_CSV, tfms=tfms, continuous=True, bs=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ftbhPMfrq_iQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idx=3\n",
        "fig,axes = plt.subplots(3,3, figsize=(9,9))\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    x,y=next(iter(md.aug_dl))\n",
        "    ima=md.val_ds.denorm(to_np(x))[idx]\n",
        "    b = bb_hw(to_np(y[idx]))\n",
        "    print(b)\n",
        "    show_img(ima, ax=ax)\n",
        "    draw_rect(ax, b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HzPYCWSSq_iX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "augs = [RandomFlip(tfm_y=TfmType.COORD),\n",
        "        RandomRotate(30, tfm_y=TfmType.COORD),\n",
        "        RandomLighting(0.1,0.1, tfm_y=TfmType.COORD)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xyH8tYdjq_iZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, tfm_y=TfmType.COORD, aug_tfms=augs)\n",
        "md = ImageClassifierData.from_csv(PATH, JPEGS, BB_CSV, tfms=tfms, continuous=True, bs=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pYX-5heOq_ic",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idx=3\n",
        "fig,axes = plt.subplots(3,3, figsize=(9,9))\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    x,y=next(iter(md.aug_dl))\n",
        "    ima=md.val_ds.denorm(to_np(x))[idx]\n",
        "    b = bb_hw(to_np(y[idx]))\n",
        "    print(b)\n",
        "    show_img(ima, ax=ax)\n",
        "    draw_rect(ax, b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Z0F_Kseq_ih",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfm_y = TfmType.COORD\n",
        "augs = [RandomFlip(tfm_y=tfm_y),\n",
        "        RandomRotate(3, p=0.5, tfm_y=tfm_y),\n",
        "        RandomLighting(0.05,0.05, tfm_y=tfm_y)]\n",
        "\n",
        "tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, tfm_y=tfm_y, aug_tfms=augs)\n",
        "md = ImageClassifierData.from_csv(PATH, JPEGS, BB_CSV, tfms=tfms, bs=bs, continuous=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YplJSd9eq_im",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "fastai let's you use a `custom_head` to add your own module on top of a convnet, instead of the adaptive pooling and fully connected net which is added by default. In this case, we don't want to do any pooling, since we need to know the activations of each grid cell.\n",
        "\n",
        "The final layer has 4 activations, one per bounding box coordinate. Our target is continuous, not categorical, so the MSE loss function used does not do any sigmoid or softmax to the module outputs."
      ]
    },
    {
      "metadata": {
        "id": "_ryTmdYkq_in",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "512*7*7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ydSF0wu1q_ir",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "head_reg4 = nn.Sequential(Flatten(), nn.Linear(25088,4))\n",
        "learn = ConvLearner.pretrained(f_model, md, custom_head=head_reg4)\n",
        "learn.opt_fn = optim.Adam\n",
        "learn.crit = nn.L1Loss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h-vEQffzq_iu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bq66r9p9q_i0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.lr_find(1e-5,100)\n",
        "learn.sched.plot(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MsnVB092q_i5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr = 2e-3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JW4Mi0lCq_jA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lr, 2, cycle_len=1, cycle_mult=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "60jKYhoiq_jD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lrs = np.array([lr/100,lr/10,lr])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "977JaNk8q_jF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.freeze_to(-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bo4e0Yvdq_jH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lrf=learn.lr_find(lrs/1000)\n",
        "learn.sched.plot(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eHu3aC34q_jJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lrs, 2, cycle_len=1, cycle_mult=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4QG0NFIeq_jM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.freeze_to(-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uf382z6aq_jO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lrs, 1, cycle_len=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cnWXn70lq_jR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('reg4')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u_dPOVYjq_jS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.load('reg4')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fk3D8eItq_jT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x,y = next(iter(md.val_dl))\n",
        "learn.model.eval()\n",
        "preds = to_np(learn.model(VV(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vru5YaSrq_jV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(3, 4, figsize=(12, 8))\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    ima=md.val_ds.denorm(to_np(x))[i]\n",
        "    b = bb_hw(preds[i])\n",
        "    ax = show_img(ima, ax=ax)\n",
        "    draw_rect(ax, b)\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RuhGozoxq_jZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Single object detection"
      ]
    },
    {
      "metadata": {
        "id": "79DXcvyOq_ja",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f_model=resnet34\n",
        "sz=224\n",
        "bs=64\n",
        "\n",
        "val_idxs = get_cv_idxs(len(trn_fns))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RhbIZCWTq_jc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, tfm_y=TfmType.COORD, aug_tfms=augs)\n",
        "md = ImageClassifierData.from_csv(PATH, JPEGS, BB_CSV, tfms=tfms,\n",
        "   bs=bs, continuous=True, val_idxs=val_idxs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UKVt5v1Tq_je",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "md2 = ImageClassifierData.from_csv(PATH, JPEGS, CSV, tfms=tfms_from_model(f_model, sz))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IyeuFCh7q_jk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A dataset can be anything with `__len__` and `__getitem__`. Here's a dataset that adds a 2nd label to an existing dataset:"
      ]
    },
    {
      "metadata": {
        "id": "HVxh2vVTq_jo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ConcatLblDataset(Dataset):\n",
        "    def __init__(self, ds, y2): self.ds,self.y2 = ds,y2\n",
        "    def __len__(self): return len(self.ds)\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        x,y = self.ds[i]\n",
        "        return (x, (y,self.y2[i]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qdFsEL7Wq_jr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We'll use it to add the classes to the bounding boxes labels."
      ]
    },
    {
      "metadata": {
        "id": "SkpP3C9rq_ju",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trn_ds2 = ConcatLblDataset(md.trn_ds, md2.trn_y)\n",
        "val_ds2 = ConcatLblDataset(md.val_ds, md2.val_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "14VaYG0qq_jz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_ds2[0][1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MJWX_8-Nq_j3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can replace the dataloaders' datasets with these new ones."
      ]
    },
    {
      "metadata": {
        "id": "ghBWBbncq_j3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "md.trn_dl.dataset = trn_ds2\n",
        "md.val_dl.dataset = val_ds2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vY7Y8XiCq_j6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have to `denorm`alize the images from the dataloader before they can be plotted."
      ]
    },
    {
      "metadata": {
        "id": "r6Dk60Pnq_j8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x,y=next(iter(md.val_dl))\n",
        "idx=3\n",
        "ima=md.val_ds.ds.denorm(to_np(x))[idx]\n",
        "b = bb_hw(to_np(y[0][idx])); b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tcp51Ce_q_j-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ax = show_img(ima)\n",
        "draw_rect(ax, b)\n",
        "draw_text(ax, b[:2], md2.classes[y[1][idx]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DHNNhAc9q_kB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We need one output activation for each class (for its probability) plus one for each bounding box coordinate. We'll use an extra linear layer this time, plus some dropout, to help us train a more flexible model."
      ]
    },
    {
      "metadata": {
        "id": "UneOEbNeq_kC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "head_reg4 = nn.Sequential(\n",
        "    Flatten(),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(25088,256),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm1d(256),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(256,4+len(cats)),\n",
        ")\n",
        "models = ConvnetBuilder(f_model, 0, 0, 0, custom_head=head_reg4)\n",
        "\n",
        "learn = ConvLearner(md, models)\n",
        "learn.opt_fn = optim.Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ojD7nrhqq_kE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def detn_loss(input, target):\n",
        "    bb_t,c_t = target\n",
        "    bb_i,c_i = input[:, :4], input[:, 4:]\n",
        "    bb_i = F.sigmoid(bb_i)*224\n",
        "    # I looked at these quantities separately first then picked a multiplier\n",
        "    #   to make them approximately equal\n",
        "    return F.l1_loss(bb_i, bb_t) + F.cross_entropy(c_i, c_t)*20\n",
        "\n",
        "def detn_l1(input, target):\n",
        "    bb_t,_ = target\n",
        "    bb_i = input[:, :4]\n",
        "    bb_i = F.sigmoid(bb_i)*224\n",
        "    return F.l1_loss(V(bb_i),V(bb_t)).data\n",
        "\n",
        "def detn_acc(input, target):\n",
        "    _,c_t = target\n",
        "    c_i = input[:, 4:]\n",
        "    return accuracy(c_i, c_t)\n",
        "\n",
        "learn.crit = detn_loss\n",
        "learn.metrics = [detn_acc, detn_l1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T9rqsPphq_kF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.lr_find()\n",
        "learn.sched.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uXPNPyddq_kH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr=1e-2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v30Sv9PSq_kP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lr, 1, cycle_len=3, use_clr=(32,5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yuwvs3mZq_kS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('reg1_0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s3AW9xODq_ka",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.freeze_to(-2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rvonKJpAq_kc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lrs = np.array([lr/100, lr/10, lr])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D5y7qFQTq_kg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.lr_find(lrs/1000)\n",
        "learn.sched.plot(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v3fLJZIJq_kk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lrs/5, 1, cycle_len=5, use_clr=(32,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZrklBQPIq_kn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('reg1_1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dY7WfwIZq_ks",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.load('reg1_1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PIYaw1mZq_kt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.unfreeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8D284E2oq_kv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.fit(lrs/10, 1, cycle_len=10, use_clr=(32,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fQi_slmMq_k0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.save('reg1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "09F0kwPuq_k5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learn.load('reg1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y5aeazfmq_k8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y = learn.predict()\n",
        "x,_ = next(iter(md.val_dl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NcpTi35-q_k_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from scipy.special import expit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nSJGvKjgq_lB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(3, 4, figsize=(12, 8))\n",
        "for i,ax in enumerate(axes.flat):\n",
        "    ima=md.val_ds.ds.denorm(to_np(x))[i]\n",
        "    bb = expit(y[i][:4])*224\n",
        "    b = bb_hw(bb)\n",
        "    c = np.argmax(y[i][4:])\n",
        "    ax = show_img(ima, ax=ax)\n",
        "    draw_rect(ax, b)\n",
        "    draw_text(ax, b[:2], md2.classes[c])\n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aniM7Tllq_lG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## End"
      ]
    },
    {
      "metadata": {
        "id": "mizmS0Ivq_lI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}